{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'images/thinking.jpeg'></img>\n",
    "\n",
    "#### Let's return to our Scenario: You work for a international political consultant, which you are suspecting is a little bit sketchy, but are still giving it a few weeks. Scott, a friendly coworker, is trying to sort through news articles to quickly filter political from non-political articles. He has heard you possess some solid NLP chops, and has asked for your help in automating the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's quickly preprocess our texts.\n",
    "import string\n",
    "text_list = [f\"{letter}.txt\" for letter in string.ascii_uppercase[:12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initial cleaning: punctuation, lowercase, stopwords, stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import regexp_tokenize\n",
    "from nltk.stem import *\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def clean_text(file_name):\n",
    "    \n",
    "    with open(f'text_examples/{file_name}', 'r') as read_file:\n",
    "        text = read_file.read().replace('\\n', ' ')\n",
    "        \n",
    "    pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "    tokens = regexp_tokenize(text, pattern) \n",
    "    \n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "    \n",
    "    p_stemmer = PorterStemmer()\n",
    "    tokens = [p_stemmer.stem(token) for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "clean_token_list = [clean_text(text) for text in text_list]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('arrest', 9),\n",
       " ('bnp', 4),\n",
       " ('commit', 4),\n",
       " ('man', 4),\n",
       " ('griffin', 3),\n",
       " ('polic', 3),\n",
       " ('follow', 3),\n",
       " ('documentari', 3),\n",
       " ('suspicion', 3),\n",
       " ('racial', 3)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "FreqDist(clean_token_list[3]).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency (TF)\n",
    "\n",
    "$\\begin{align}\n",
    " tf_{i,j} = \\dfrac{n_{i,j}}{\\displaystyle \\sum_k n_{i,j} }\n",
    "\\end{align} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TF for two documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of all words across all documents\n",
    "docs = clean_token_list[:2]\n",
    "\n",
    "def vanilla_tf():\n",
    "    \n",
    "\n",
    "    return tf\n",
    "\n",
    "term_f = []\n",
    "for doc in docs:\n",
    "    term_f.append(vanilla_tf())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency (IDF)\n",
    "\n",
    "$\\begin{align}\n",
    "idf(w) = \\log \\dfrac{N}{df_t}\n",
    "\\end{align} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create inverse document frequencies\n",
    "import math\n",
    "\n",
    "def vanilla_idf(all_words, all_bows):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate inverse document frequency from scratch\n",
    "    for demonstration.\n",
    "    \n",
    "    parameters:\n",
    "    all_words: A set of all tokens across the texts\n",
    "    all_bows: a list of all tokens in each text.\n",
    "    \n",
    "    returns:\n",
    "    an inverse document frequency list with indices \n",
    "    corresponding to the tokens in all_words.\n",
    "    \"\"\"\n",
    "    \n",
    "    idf= []\n",
    "    \n",
    "    for word in all_words:\n",
    "        count = 0\n",
    "        for doc in all_bows:\n",
    "            if word in doc:\n",
    "                count += 1\n",
    "        idf.append(math.log10(len(all_bows)/count))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return idf\n",
    "\n",
    "vanilla_idf = vanilla_idf(all_tokens, docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_tf_idf = []\n",
    "for doc in term_f:\n",
    "    doc_tf_idf = []\n",
    "    for word, idf in zip(doc, vanilla_idf):\n",
    "        doc_tf_idf.append(word * idf)\n",
    "    vanilla_tf_idf.append(doc_tf_idf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 201)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "vanilla_df = pd.DataFrame(vanilla_tf_idf)\n",
    "vanilla_df.columns = all_tokens\n",
    "vanilla_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://media.giphy.com/media/Rl9Yqavfj2Ula/giphy.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_labels = [1, 1, 0, 1, 0, 0, 0, 1 ,0 ,0, 1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "clean_token_strings = []\n",
    "for doc in clean_token_list:\n",
    "    clean_token_strings.append((' ').join(doc))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(clean_token_strings, text_labels, test_size = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data began as a sparse matrix, which is a matrix with far more 0 values than not 0 values\n",
    "More about it herehttps://docs.scipy.org/doc/scipy/reference/sparse.html\n",
    "To make better sense of it, we can put it back into a dataframe.\n",
    "Caution: moving from sparse matrix to array format will take much more memory to perform operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, results, but very confident because of the small sample size. Sorry, Scott. Next time give me more to work with!\n",
    "<img src = 'images/thinking.jpeg'></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "## let's try another, larger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "cats = ['rec.sport.baseball','rec.sport.hockey']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',categories=cats)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test',categories=cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9748743718592965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[386,  11],\n",
       "       [  9, 390]])"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "X_train = cv.fit_transform(newsgroups_train.data)\n",
    "y_train = newsgroups_train.target\n",
    "mnb.fit(X_train, y_train )\n",
    "y_hat = mnb.predict(cv.transform(newsgroups_test.data))\n",
    "print(accuracy_score(newsgroups_test.target, y_hat))\n",
    "confusion_matrix(newsgroups_test.target, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8793969849246231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmaxbarry/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[376,  21],\n",
       "       [ 75, 324]])"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "X_train = cv.fit_transform(newsgroups_train.data)\n",
    "y_train = newsgroups_train.target\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train )\n",
    "y_hat = rf.predict(cv.transform(newsgroups_test.data))\n",
    "print(accuracy_score(newsgroups_test.target, y_hat))\n",
    "confusion_matrix(newsgroups_test.target, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -7.00778466,  -8.22312122, -11.0853221 , ..., -11.0853221 ,\n",
       "        -11.77846928, -11.77846928]])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "55\n",
      "games\n",
      "year\n",
      "article\n",
      "25\n",
      "season\n",
      "writes\n",
      "university\n",
      "nhl\n",
      "10\n",
      "play\n",
      "game\n",
      "organization\n",
      "lines\n",
      "subject\n",
      "hockey\n",
      "ca\n",
      "team\n",
      "edu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "feature_names = np.array(cv.get_feature_names())\n",
    "feature_importances = np.argsort(mnb.coef_[0])[-20:]\n",
    "\n",
    "for idx in feature_importances:\n",
    "    print(feature_names[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weird stuff going on in here. Numbers.\n",
    "# What can we do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can tell how similar two documents are to one another, normalizing for size, by taking the cosine similarity of the two. \n",
    "\n",
    "This number will range from [0,1], with 0 being not similar whatsoever, and 1 being the exact same. A potential application of cosine similarity is a basic recommendation engine. If you wanted to recommend articles that are most similar to other articles, you could talk the cosine similarity of all articles and return the highest one.\n",
    "\n",
    "<img src=\"images/cosine-similarity.png\">\n",
    "<img src=\"images/better_cos_similarity.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "samples = ['I ate a burger at burger queen and it was very good.',\n",
    "           'I ate a hot dog at burger prince and it was bad',\n",
    "          'I drove a racecar through your kitchen door',\n",
    "          'I ate a hot dog at burger king and it was bad. I ate a burger at burger queen and it was very good']\n",
    "\n",
    "cv.fit(samples)\n",
    "text_data = cv.transform(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91413793]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "## the 0th and 2nd index lines are very different, a number close to 0\n",
    "cosine_similarity(text_data[0],text_data[3])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
